{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a6d38e6",
   "metadata": {},
   "source": [
    "# Import DLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89126aec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.2.2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edwar\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\__init__.py:81: UserWarning: \n",
      "        As PyTorch is not installed, unsupervised identity learning will not be available.\n",
      "        Please run `pip install torch`, or ignore this warning.\n",
      "        \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut\n",
    "from PathGeneral_Func import GetFilePaths\n",
    "import os\n",
    "#consider removing PathGeneral_Func above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b190c29e",
   "metadata": {},
   "source": [
    "   ### Select config file and unfiltered videos to refine post-analysis\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cc16753",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtkinter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m filedialog\n\u001b[0;32m     10\u001b[0m config \u001b[38;5;241m=\u001b[39m filedialog\u001b[38;5;241m.\u001b[39maskopenfilenames(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChoose the config file of your DeepLabCut project:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m path_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(Videos_Paths)\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "#Videos_Dir      = r\"C:\\Users\\Edwar\\Documents\\deeplabcut\\Motor videos for training\\DLC Motor Training Set\\\\\"\n",
    "Videos_Dir      = r\"C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\"\n",
    "\n",
    "Videos_Paths    = GetFilePaths(Videos_Dir, '.avi')\n",
    "#Videos_Paths = GetFilePaths(Videos_Dir, '.avi') # If only 1 movie uses function in cell above\n",
    "\n",
    "# Select config file from project #\n",
    "from tkinter import filedialog\n",
    "\n",
    "config = filedialog.askopenfilenames(title='Choose the config file of your DeepLabCut project:')\n",
    "path_config_file = config[0]\n",
    "\n",
    "print(Videos_Paths)\n",
    "\n",
    "# consider selecting all paths above. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a26a9a3",
   "metadata": {},
   "source": [
    "### Extract outliers for refinment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eae887bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edwar\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\outlier_frames.py:401: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
      "  sum_ = temp_dt.sum(axis=1, level=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method  jump  found  8525  putative outlier frames.\n",
      "Do you want to proceed with extracting  6  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n",
      "Loading video...\n",
      "Duration of video [s]:  310.06666666666666 , recorded @  30.0 fps!\n",
      "Overall # of frames:  9302 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 310.07  seconds.\n",
      "Extracting and downsampling... 8525  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8525it [03:50, 36.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [4695, 6760, 4456, 9098, 3768, 2118]\n",
      "Attempting to create a symbolic link of the video ...\n",
      "Symlink creation impossible (exFat architecture?): cutting/pasting the video instead.\n",
      "C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\04102022_M00817915_1R_NBH_MET_LOCOMOTION_WK16.avi moved to C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\04102022_M00817915_1R_NBH_MET_LOCOMOTION_WK16.avi\n",
      "New videos were added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\04102022_M00817915_1R_NBH_MET_LOCOMOTION_WK16.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edwar\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\outlier_frames.py:401: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
      "  sum_ = temp_dt.sum(axis=1, level=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method  jump  found  8252  putative outlier frames.\n",
      "Do you want to proceed with extracting  6  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n",
      "Loading video...\n",
      "Duration of video [s]:  310.1 , recorded @  30.0 fps!\n",
      "Overall # of frames:  9303 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 310.1  seconds.\n",
      "Extracting and downsampling... 8252  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8252it [03:52, 35.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [7889, 6488, 4951, 942, 6049, 8267]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edwar\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\outlier_frames.py:401: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
      "  sum_ = temp_dt.sum(axis=1, level=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to create a symbolic link of the video ...\n",
      "Symlink creation impossible (exFat architecture?): cutting/pasting the video instead.\n",
      "C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\04102022_M00817934_NM_NBH_FLX_LOCOMOTION_WK16.avi moved to C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\04102022_M00817934_NM_NBH_FLX_LOCOMOTION_WK16.avi\n",
      "New videos were added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\04102022_M00817934_NM_NBH_FLX_LOCOMOTION_WK16.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  1918  putative outlier frames.\n",
      "Do you want to proceed with extracting  6  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n",
      "Frames from video 060522_MC_NBH_M00708458_1L_CD_19wk  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  70.1 , recorded @  30.0 fps!\n",
      "Overall # of frames:  2103 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 70.1  seconds.\n",
      "Extracting and downsampling... 1918  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1918it [01:20, 23.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [1529, 168, 408, 1946, 14, 1655]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edwar\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\outlier_frames.py:401: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
      "  sum_ = temp_dt.sum(axis=1, level=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to create a symbolic link of the video ...\n",
      "Symlink creation impossible (exFat architecture?): cutting/pasting the video instead.\n",
      "C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\060522_MC_NBH_M00708458_1L_CD_19wk.avi moved to C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\060522_MC_NBH_M00708458_1L_CD_19wk.avi\n",
      "New videos were added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\060522_MC_NBH_M00708458_1L_CD_19wk.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  1797  putative outlier frames.\n",
      "Do you want to proceed with extracting  6  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n",
      "Frames from video 061022_MC_RML_M00817907_NM_CD_SEM100_16wk  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  70.1 , recorded @  30.0 fps!\n",
      "Overall # of frames:  2103 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 70.1  seconds.\n",
      "Extracting and downsampling... 1797  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1797it [00:58, 30.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [1324, 1185, 1509, 491, 859, 810]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edwar\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\outlier_frames.py:401: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
      "  sum_ = temp_dt.sum(axis=1, level=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to create a symbolic link of the video ...\n",
      "Symlink creation impossible (exFat architecture?): cutting/pasting the video instead.\n",
      "C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\061022_MC_RML_M00817907_NM_CD_SEM100_16wk.avi moved to C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\061022_MC_RML_M00817907_NM_CD_SEM100_16wk.avi\n",
      "New videos were added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\061022_MC_RML_M00817907_NM_CD_SEM100_16wk.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  1908  putative outlier frames.\n",
      "Do you want to proceed with extracting  6  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n",
      "Frames from video 061022_MC_RML_M00817965_1L_CD_SLN_16wk  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  70.06666666666666 , recorded @  30.0 fps!\n",
      "Overall # of frames:  2102 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 70.07  seconds.\n",
      "Extracting and downsampling... 1908  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1908it [01:01, 31.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [16, 931, 191, 152, 1219, 1651]\n",
      "Frame could not be read.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edwar\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\outlier_frames.py:401: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
      "  sum_ = temp_dt.sum(axis=1, level=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to create a symbolic link of the video ...\n",
      "Symlink creation impossible (exFat architecture?): cutting/pasting the video instead.\n",
      "C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\061022_MC_RML_M00817965_1L_CD_SLN_16wk.avi moved to C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\061022_MC_RML_M00817965_1L_CD_SLN_16wk.avi\n",
      "New videos were added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\061022_MC_RML_M00817965_1L_CD_SLN_16wk.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  1837  putative outlier frames.\n",
      "Do you want to proceed with extracting  6  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n",
      "Frames from video 071022_MC_NBH_M00817922_NM_CD_MET_16wk  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  70.06666666666666 , recorded @  30.0 fps!\n",
      "Overall # of frames:  2102 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 70.07  seconds.\n",
      "Extracting and downsampling... 1837  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1837it [01:11, 25.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [34, 1220, 391, 586, 1953, 867]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edwar\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\outlier_frames.py:401: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
      "  sum_ = temp_dt.sum(axis=1, level=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to create a symbolic link of the video ...\n",
      "Symlink creation impossible (exFat architecture?): cutting/pasting the video instead.\n",
      "C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\071022_MC_NBH_M00817922_NM_CD_MET_16wk.avi moved to C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\071022_MC_NBH_M00817922_NM_CD_MET_16wk.avi\n",
      "New videos were added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\071022_MC_NBH_M00817922_NM_CD_MET_16wk.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  1744  putative outlier frames.\n",
      "Do you want to proceed with extracting  6  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n",
      "Frames from video 071022_MC_NBH_M00817968_1L_CD_VEH_16wk  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  70.1 , recorded @  30.0 fps!\n",
      "Overall # of frames:  2103 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 70.1  seconds.\n",
      "Extracting and downsampling... 1744  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1744it [00:52, 33.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [2095, 2099, 1849, 589, 177, 1430]\n",
      "Frame could not be read.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edwar\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\outlier_frames.py:401: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
      "  sum_ = temp_dt.sum(axis=1, level=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to create a symbolic link of the video ...\n",
      "Symlink creation impossible (exFat architecture?): cutting/pasting the video instead.\n",
      "C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\071022_MC_NBH_M00817968_1L_CD_VEH_16wk.avi moved to C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\071022_MC_NBH_M00817968_1L_CD_VEH_16wk.avi\n",
      "New videos were added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\071022_MC_NBH_M00817968_1L_CD_VEH_16wk.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  1815  putative outlier frames.\n",
      "Do you want to proceed with extracting  6  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n",
      "Frames from video 071022_MC_RML_M00817920_1L_CD_MET_16wk  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  70.1 , recorded @  30.0 fps!\n",
      "Overall # of frames:  2103 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 70.1  seconds.\n",
      "Extracting and downsampling... 1815  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1815it [01:20, 22.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [977, 661, 461, 29, 1300, 1544]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edwar\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\outlier_frames.py:401: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
      "  sum_ = temp_dt.sum(axis=1, level=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to create a symbolic link of the video ...\n",
      "Symlink creation impossible (exFat architecture?): cutting/pasting the video instead.\n",
      "C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\071022_MC_RML_M00817920_1L_CD_MET_16wk.avi moved to C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\071022_MC_RML_M00817920_1L_CD_MET_16wk.avi\n",
      "New videos were added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\071022_MC_RML_M00817920_1L_CD_MET_16wk.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  1867  putative outlier frames.\n",
      "Do you want to proceed with extracting  6  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n",
      "Frames from video 071022_MC_RML_M00817976_NM_CD_VEH_16wk  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  70.13333333333334 , recorded @  30.0 fps!\n",
      "Overall # of frames:  2104 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 70.13  seconds.\n",
      "Extracting and downsampling... 1867  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1867it [01:03, 29.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [693, 1656, 9, 1056, 73, 994]\n",
      "Attempting to create a symbolic link of the video ...\n",
      "Symlink creation impossible (exFat architecture?): cutting/pasting the video instead.\n",
      "C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\071022_MC_RML_M00817976_NM_CD_VEH_16wk.avi moved to C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\071022_MC_RML_M00817976_NM_CD_VEH_16wk.avi\n",
      "New videos were added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\071022_MC_RML_M00817976_NM_CD_VEH_16wk.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  1976  putative outlier frames.\n",
      "Do you want to proceed with extracting  6  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n",
      "Frames from video 080522_MC_NBH_M00708460_NM_CD_19wk  already extracted (more will be added)!\n",
      "Loading video...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edwar\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\outlier_frames.py:401: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
      "  sum_ = temp_dt.sum(axis=1, level=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of video [s]:  70.06666666666666 , recorded @  30.0 fps!\n",
      "Overall # of frames:  2102 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 70.07  seconds.\n",
      "Extracting and downsampling... 1976  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1976it [01:22, 23.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [1794, 1870, 1664, 299, 1250, 1523]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edwar\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\outlier_frames.py:401: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
      "  sum_ = temp_dt.sum(axis=1, level=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to create a symbolic link of the video ...\n",
      "Symlink creation impossible (exFat architecture?): cutting/pasting the video instead.\n",
      "C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\080522_MC_NBH_M00708460_NM_CD_19wk.avi moved to C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\080522_MC_NBH_M00708460_NM_CD_19wk.avi\n",
      "New videos were added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\080522_MC_NBH_M00708460_NM_CD_19wk.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  1663  putative outlier frames.\n",
      "Do you want to proceed with extracting  6  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n",
      "Frames from video 080522_MC_NBH_M00708471_1R_CD_MET_19wk  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  70.1 , recorded @  30.0 fps!\n",
      "Overall # of frames:  2103 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 70.1  seconds.\n",
      "Extracting and downsampling... 1663  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1663it [01:10, 23.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [1698, 1056, 639, 2099, 1754, 158]\n",
      "Frame could not be read.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edwar\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\outlier_frames.py:401: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
      "  sum_ = temp_dt.sum(axis=1, level=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to create a symbolic link of the video ...\n",
      "Symlink creation impossible (exFat architecture?): cutting/pasting the video instead.\n",
      "C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\080522_MC_NBH_M00708471_1R_CD_MET_19wk.avi moved to C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\080522_MC_NBH_M00708471_1R_CD_MET_19wk.avi\n",
      "New videos were added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\080522_MC_NBH_M00708471_1R_CD_MET_19wk.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  1923  putative outlier frames.\n",
      "Do you want to proceed with extracting  6  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n",
      "Frames from video 090622_MC_RML_M00726222_1L_CD_MET_19wk  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  70.1 , recorded @  30.0 fps!\n",
      "Overall # of frames:  2103 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 70.1  seconds.\n",
      "Extracting and downsampling... 1923  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1923it [01:01, 31.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [1651, 2002, 489, 1840, 164, 913]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edwar\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\outlier_frames.py:401: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
      "  sum_ = temp_dt.sum(axis=1, level=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to create a symbolic link of the video ...\n",
      "Symlink creation impossible (exFat architecture?): cutting/pasting the video instead.\n",
      "C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\090622_MC_RML_M00726222_1L_CD_MET_19wk.avi moved to C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\090622_MC_RML_M00726222_1L_CD_MET_19wk.avi\n",
      "New videos were added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\090622_MC_RML_M00726222_1L_CD_MET_19wk.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  1829  putative outlier frames.\n",
      "Do you want to proceed with extracting  6  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n",
      "Frames from video 090622_MC_RML_M00726224_NM_CD_MET_19wk  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  70.1 , recorded @  30.0 fps!\n",
      "Overall # of frames:  2103 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 70.1  seconds.\n",
      "Extracting and downsampling... 1829  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1459it [00:51, 28.54it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Project_Dir = r\"C:\\Users\\Edwar\\Documents\\deeplabcut\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#Project_Dir = r\"C:\\Users\\Edwar\\Documents\\deeplabcut\"\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mdeeplabcut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_outlier_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_config_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVideos_Paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautomatic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\outlier_frames.py:471\u001b[0m, in \u001b[0;36mextract_outlier_frames\u001b[1;34m(config, videos, videotype, shuffle, trainingsetindex, outlieralgorithm, comparisonbodyparts, epsilon, p_bound, ARdegree, MAdegree, alpha, extractionalgorithm, automatic, cluster_resizewidth, cluster_color, opencv, savelabeled, copy_videos, destfolder, modelprefix, track_method)\u001b[0m\n\u001b[0;32m    462\u001b[0m     askuser \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJa\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    465\u001b[0m     askuser \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m askuser \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m ):  \u001b[38;5;66;03m# multilanguage support :)\u001b[39;00m\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;66;03m# Now extract from those Indices!\u001b[39;00m\n\u001b[1;32m--> 471\u001b[0m     \u001b[43mExtractFramesbasedonPreselection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIndices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextractionalgorithm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvideo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopencv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcluster_resizewidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcluster_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43msavelabeled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy_videos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy_videos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNothing extracted, please change the parameters and start again...\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    487\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\outlier_frames.py:666\u001b[0m, in \u001b[0;36mExtractFramesbasedonPreselection\u001b[1;34m(Index, extractionalgorithm, data, video, cfg, config, opencv, cluster_resizewidth, cluster_color, savelabeled, with_annotations, copy_videos)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m extractionalgorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkmeans\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    665\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m opencv:\n\u001b[1;32m--> 666\u001b[0m         frames2pick \u001b[38;5;241m=\u001b[39m \u001b[43mframeselectiontools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKmeansbasedFrameselectioncv2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnumframes2extract\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcropping\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m            \u001b[49m\u001b[43mIndex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresizewidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcluster_resizewidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcluster_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    678\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcropping\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32m~\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\utils\\frameselectiontools.py:296\u001b[0m, in \u001b[0;36mKmeansbasedFrameselectioncv2\u001b[1;34m(cap, numframes2pick, start, stop, crop, coords, Index, step, resizewidth, batchsize, max_iter, color)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m counter, index \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(Index)):\n\u001b[1;32m--> 296\u001b[0m         \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_to_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# extract a particular frame\u001b[39;00m\n\u001b[0;32m    297\u001b[0m         frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread_frame()\n\u001b[0;32m    298\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m frame \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\utils\\auxfun_videos.py:120\u001b[0m, in \u001b[0;36mVideoReader.set_to_frame\u001b[1;34m(self, ind)\u001b[0m\n\u001b[0;32m    115\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    116\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex exceeds the total number of frames. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting to last frame instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m     )\n\u001b[0;32m    119\u001b[0m     ind \u001b[38;5;241m=\u001b[39m last_frame\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvideo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCAP_PROP_POS_FRAMES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mind\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Project_Dir = r\"C:\\Users\\Edwar\\Documents\\deeplabcut\"\n",
    "#Project_Dir = r\"C:\\Users\\Edwar\\Documents\\deeplabcut\"\n",
    "\n",
    "deeplabcut.extract_outlier_frames(path_config_file, Videos_Paths, automatic=True)\n",
    "\n",
    "#Project_Name = 'DLC_TRN_MOTOR_021022'\n",
    "#Experimenter = \"ECH\"\n",
    "\n",
    "#Config_Path = deeplabcut.create_new_project(Project_Name, Experimenter, \n",
    "                                            #Videos_Paths, videotype = '.avi', copy_videos = True,\n",
    "                                            #working_directory = Project_Dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4098862",
   "metadata": {},
   "source": [
    "### Refine labels that have been extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4feae671",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing... The refined labels are stored in a subdirectory under labeled-data. Use the function 'merge_datasets' to augment the training dataset, and then re-train a network using create_training_dataset followed by train_network!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.refine_labels(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1674d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.check_labels(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "988b3e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data sets and updated refinement iteration to 1.\n",
      "Now you can create a new training set for the expanded annotated images (use create_training_dataset).\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.merge_datasets(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6a50f4",
   "metadata": {},
   "source": [
    "# Transfer to HPC for re-training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b0819b",
   "metadata": {},
   "source": [
    "### Use deeplabcut.analysevideos on HPC "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a810fe5",
   "metadata": {},
   "source": [
    "### Add plot trajectories for each video in video directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92a92238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\04102022_M00817915_1R_NBH_MET_LOCOMOTION_WK16.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\04102022_M00817934_NM_NBH_FLX_LOCOMOTION_WK16.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\060522_MC_NBH_M00708458_1L_CD_19wk.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\061022_MC_RML_M00817907_NM_CD_SEM100_16wk.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\061022_MC_RML_M00817965_1L_CD_SLN_16wk.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\071022_MC_NBH_M00817922_NM_CD_MET_16wk.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\071022_MC_NBH_M00817968_1L_CD_VEH_16wk.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\071022_MC_RML_M00817920_1L_CD_MET_16wk.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\071022_MC_RML_M00817976_NM_CD_VEH_16wk.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\080522_MC_NBH_M00708460_NM_CD_19wk.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\080522_MC_NBH_M00708471_1R_CD_MET_19wk.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\090622_MC_RML_M00726222_1L_CD_MET_19wk.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\090622_MC_RML_M00726224_NM_CD_MET_19wk.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\090622_MC_RML_M00726277_1R_CD_FLX_19wk.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\120622_MC_RML_M00726242_NM_CD_SLN_19wk.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\120622_MC_RML_M00726253_1R_CD_FLX_19wk.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\16092022_M0017919_NM_RML_MET_MOTOR_WK13.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\16092022_M0017934_NM_NBH_FLX_MOTOR_WK13.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\16092022_M0017936_1R_NBH_FLX_MOTOR_WK13.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\16092022_M0017939_1R_RML_VEH_MOTOR_WK13.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\16092022_M0017962_1L_NBH_VEH_MOTOR_WK13.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\16092022_M0017965_1L_RML_SAL_MOTOR_WK13.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\16092022_M0017968_1L_NBH_VEH_MOTOR_WK13.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\200622_MC_RML_M00726228_1L_CD_VEH_20w.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\210622_MC_NBH_M00726218_NM_CD_SLN_20wk.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\210622_MC_NBH_M00726260_NM_CD_SEM_20wk.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\210622_MC_RML_M00726242_NM_CD_SLN_20w.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\210622_MC_RML_M00726252_1L_CD_FLX_20w.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\210622_MC_RML_M00726272_NM_CD_SLN_20w.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\210622_MC_RML_M00726273_1L_CD_SLN_20w.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\210622_MC_RML_M00726274_NM_CD_SLN_20w.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\220522_MC_NBH_M00726237_1L_CD_SEM_16wk.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\220522_MC_NBH_M00726262_1R_CD_SEM_16wk.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\220522_MC_RML_M00726245_NM_CD_FLX_16wk.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\220622_MC_RML_M00726239_NM_CD_SLN_20w_R2.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\220622_MC_RML_M00726240_1L_CD_SLN_20w.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\220622_MC_RML_M00726241_1R_CD_SLN_20w.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\220622_MC_RML_M00726242_NM_CD_SLN_20w.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\220622_MC_RML_M00726243_1L_CD_SLN_20w.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\220622_MC_RML_M00726244_1R_CD_SLN_20w.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\230522_MC_RML_M00726223_1R_CD_MET_16wk.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\271022_MC_NBH_M00817959_1L_FLX_WK19.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\271022_MC_NBH_M00817960_1R_FLX_WK19.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\271022_MC_NBH_M00817968_1L_VEH_WK19.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\281022_MC_NBH_M00817947_1L_VEH_WK19.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989854_NM_RML_SEMA100_MOTOR_WEEK_19_19072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989855_TL_RML_SEMA100_MOTOR_WEEK_19_19072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989856_TR_RML_SEMA100_MOTOR_WEEK_19_19072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989857_NM_RML_PIO_MOTOR_WEEK_19_18072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989858_TL_RML_PIO_MOTOR_WEEK_19_18072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989859_TR_RML_PIO_MOTOR_WEEK_19_18072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989860_NM_RML_PIO_MOTOR_WEEK_19_18072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989861_TL_RML_PIO_MOTOR_WEEK_19_18072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989862_TR_RML_PIO_MOTOR_WEEK_19_18072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989866_NM_RML_SALINE_MOTOR_WEEK_19_18072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989867_TL_RML_SALINE_MOTOR_WEEK_19_18072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989868_TR_RML_SALINE_MOTOR_WEEK_19_18072023.avi and data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989869_NM_RML_SEMA100_MOTOR_WEEK_19_19072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989870_TL_RML_SEMA100_MOTOR_WEEK_19_19072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989871_TR_RML_SEMA100_MOTOR_WEEK_19_19072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989872_NM_RML_CD_ONLY_MOTOR_WEEK_19_19072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989873_TL_RML_CD_ONLY_MOTOR_WEEK_19_19072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989874_TR_RML_CD_ONLY_MOTOR_WEEK_19_19072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989881_NM_RML_PIO_MOTOR_WEEK_19_19072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989882_TL_RML_PIO_MOTOR_WEEK_19_19072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989883_TR_RML_PIO_MOTOR_WEEK_19_19072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989884_NM_RML_SEMA100_MOTOR_WEEK_19_18072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989885_TL_RML_SEMA100_MOTOR_WEEK_19_18072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989886_TR_RML_SEMA100_MOTOR_WEEK_19_18072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989893_NM_RML_PIO_MOTOR_WEEK_19_18072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989894_TL_RML_PIO_MOTOR_WEEK_19_18072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989895_TR_RML_PIO_MOTOR_WEEK_19_18072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989902_NM_RML_SEMA100_MOTOR_WEEK_19_18072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989903_TL_RML_SEMA100_MOTOR_WEEK_19_18072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989904_TR_RML_SEMA100_MOTOR_WEEK_19_18072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989905_NM_RML_CD_ONLY_MOTOR_WEEK_19_18072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989906_TL_RML_CD_ONLY_MOTOR_WEEK_19_18072023.avi and data.\n",
      "Loading  C:\\Users\\Edwar\\Documents\\deeplabcut\\DLC_TRN_MOTOR_021022-ECH-2022-11-02\\videos\\SP131391_M00989907_TR_RML_CD_ONLY_MOTOR_WEEK_19_18072023.avi and data.\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n"
     ]
    }
   ],
   "source": [
    "from tkinter import filedialog\n",
    "import deeplabcut\n",
    "\n",
    "# Open a file dialog to select the DeepLabCut configuration file\n",
    "config_archive = filedialog.askopenfilenames(title='Choose the config file of your DeepLabCut project:')\n",
    "path_config_file = config_archive[0] if config_archive else None\n",
    "\n",
    "if path_config_file:\n",
    "    deeplabcut.plot_trajectories(path_config_file, Videos_Paths, videotype='.avi', track_method='box')\n",
    "else:\n",
    "    print(\"No config file selected. Please select a file.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-DEEPLABCUT] *",
   "language": "python",
   "name": "conda-env-.conda-DEEPLABCUT-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
